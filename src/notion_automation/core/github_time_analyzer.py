"""
3-Part Daily Reflection System - GitHub ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ

Task 4.1.1: ì‹œê°„ëŒ€ë³„ GitHub í™œë™ ìˆ˜ì§‘ ì½”ì–´ í•¨ìˆ˜ ê°œë°œ
- codebase_upgrade_analysis.md ê¸°ë°˜ ì‹œê°„ëŒ€ë³„ ë¶„ë¥˜ ë¡œì§ êµ¬í˜„
- ê¸°ì¡´ í•˜ë£¨ ì „ì²´ ìˆ˜ì§‘ â†’ ì‹œê°„ëŒ€ë³„ ì„¸ë¶„í™”
- GitHub MCPë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì‹œê°„ëŒ€ë³„ í™œë™ ì¶”ì 
"""

import os
import sys
import json
import logging
from datetime import datetime, date, timedelta
from typing import Dict, List, Any, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

# ë¡œê±° ì„¤ì •
from src.notion_automation.utils.logger import ThreePartLogger

logger = ThreePartLogger("github_time_analyzer")

class GitHubTimeAnalyzer:
    """GitHub ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, owner: str = None, repo: str = None, token: str = None):
        """
        GitHub ì‹œê°„ëŒ€ë³„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            owner: GitHub ì €ì¥ì†Œ ì†Œìœ ì
            repo: GitHub ì €ì¥ì†Œ ì´ë¦„  
            token: GitHub ì•¡ì„¸ìŠ¤ í† í°
        """
        self.owner = owner or os.getenv("GITHUB_OWNER", "user")
        self.repo = repo or os.getenv("GITHUB_REPO", "repository")
        self.token = token or os.getenv("GITHUB_TOKEN")
        
        # 3-Part ì‹œê°„ëŒ€ ì •ì˜
        self.time_ranges = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": {"start": 9, "end": 12, "type": "morning"},
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": {"start": 13, "end": 17, "type": "afternoon"},
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": {"start": 19, "end": 22, "type": "evening"}
        }
        
        # GitHub í™œë™ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
        self.activity_weights = {
            "commits": 3,      # ì»¤ë°‹ì´ ê°€ì¥ ì¤‘ìš”
            "issues": 2,       # ì´ìŠˆ ìƒì„±/ê´€ë¦¬
            "pull_requests": 4, # PRì€ í˜‘ì—…ì˜ í•µì‹¬
            "code_reviews": 3,  # ì½”ë“œ ë¦¬ë·°
            "releases": 5       # ë¦´ë¦¬ì¦ˆëŠ” ë†’ì€ ê°€ì¹˜
        }

    def get_time_part_activities(self, target_date: date, time_part: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ë‚ ì§œì˜ íŠ¹ì • ì‹œê°„ëŒ€ GitHub í™œë™ ìˆ˜ì§‘
        
        Args:
            target_date: ë¶„ì„í•  ë‚ ì§œ
            time_part: ì‹œê°„ëŒ€ ("ğŸŒ… ì˜¤ì „ìˆ˜ì—…", "ğŸŒ ì˜¤í›„ìˆ˜ì—…", "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ")
            
        Returns:
            ì‹œê°„ëŒ€ë³„ GitHub í™œë™ ë°ì´í„°
        """
        logger.info(f"GitHub ì‹œê°„ëŒ€ë³„ í™œë™ ìˆ˜ì§‘ ì‹œì‘: {target_date} {time_part}")
        
        if time_part not in self.time_ranges:
            logger.error(f"ì˜ëª»ëœ ì‹œê°„ëŒ€: {time_part}")
            return {}
        
        time_config = self.time_ranges[time_part]
        start_hour = time_config["start"]
        end_hour = time_config["end"]
        
        try:
            # ì‹œê°„ëŒ€ë³„ í™œë™ ìˆ˜ì§‘ (í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜)
            activities = {
                "date": str(target_date),
                "time_part": time_part,
                "time_range": f"{start_hour:02d}:00-{end_hour:02d}:00",
                "owner": self.owner,
                "repo": self.repo,
                "commits": self._get_commits_by_time_range(target_date, start_hour, end_hour),
                "issues": self._get_issues_by_time_range(target_date, start_hour, end_hour),
                "pull_requests": self._get_prs_by_time_range(target_date, start_hour, end_hour),
                "code_reviews": self._get_reviews_by_time_range(target_date, start_hour, end_hour),
                "productive_score": 0  # ë‚˜ì¤‘ì— ê³„ì‚°
            }
            
            # ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚°
            activities["productive_score"] = self._calculate_time_part_productivity(activities)
            
            logger.info(f"GitHub í™œë™ ìˆ˜ì§‘ ì™„ë£Œ: {activities['productive_score']}ì ")
            return activities
            
        except Exception as e:
            logger.error(f"GitHub í™œë™ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {}

    def _get_commits_by_time_range(self, target_date: date, start_hour: int, end_hour: int) -> List[Dict[str, Any]]:
        """ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” GitHub MCP ë„êµ¬ ì‚¬ìš©
        # github_repo ë„êµ¬ë‚˜ ì‹¤ì œ GitHub API í˜¸ì¶œ
        
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° - ì‹œê°„ëŒ€ë³„ íŠ¹ì„± ë°˜ì˜
        if start_hour == 9:  # ì˜¤ì „ìˆ˜ì—…
            commits = [
                {
                    "sha": "abc123",
                    "message": "ìˆ˜ì—… ë‚´ìš© ì •ë¦¬ ë° ê¸°ì´ˆ ê°œë… ì¶”ê°€",
                    "timestamp": f"{target_date}T10:30:00Z",
                    "author": self.owner,
                    "additions": 45,
                    "deletions": 12,
                    "files_changed": 3,
                    "type": "í•™ìŠµì •ë¦¬"
                },
                {
                    "sha": "def456", 
                    "message": "Python ê¸°ì´ˆ ë¬¸ë²• ì˜ˆì œ ì¶”ê°€",
                    "timestamp": f"{target_date}T11:15:00Z",
                    "author": self.owner,
                    "additions": 23,
                    "deletions": 5,
                    "files_changed": 2,
                    "type": "ì˜ˆì œì½”ë“œ"
                }
            ]
        elif start_hour == 13:  # ì˜¤í›„ìˆ˜ì—…
            commits = [
                {
                    "sha": "ghi789",
                    "message": "HTML ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì™„ì„±",
                    "timestamp": f"{target_date}T14:20:00Z",
                    "author": self.owner,
                    "additions": 78,
                    "deletions": 23,
                    "files_changed": 5,
                    "type": "ì‹¤ìŠµì™„ì„±"
                },
                {
                    "sha": "jkl012",
                    "message": "CSS ìŠ¤íƒ€ì¼ë§ ê°œì„  ë° ë°˜ì‘í˜• ì ìš©",
                    "timestamp": f"{target_date}T16:45:00Z",
                    "author": self.owner,
                    "additions": 134,
                    "deletions": 67,
                    "files_changed": 8,
                    "type": "ê¸°ëŠ¥ê°œì„ "
                }
            ]
        else:  # ì €ë…ììœ¨í•™ìŠµ
            commits = [
                {
                    "sha": "mno345",
                    "message": "ê°œì¸ í”„ë¡œì íŠ¸ - ì‚¬ìš©ì ì¸ì¦ ê¸°ëŠ¥ êµ¬í˜„",
                    "timestamp": f"{target_date}T20:10:00Z",
                    "author": self.owner,
                    "additions": 189,
                    "deletions": 45,
                    "files_changed": 12,
                    "type": "ê°œì¸í”„ë¡œì íŠ¸"
                },
                {
                    "sha": "pqr678",
                    "message": "ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ í•´ê²° ë° ìµœì í™”",
                    "timestamp": f"{target_date}T21:30:00Z",
                    "author": self.owner,
                    "additions": 67,
                    "deletions": 23,
                    "files_changed": 4,
                    "type": "ì•Œê³ ë¦¬ì¦˜"
                }
            ]
        
        logger.info(f"ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ìˆ˜ì§‘: {len(commits)}ê°œ ({start_hour}:00-{end_hour}:00)")
        return commits

    def _get_issues_by_time_range(self, target_date: date, start_hour: int, end_hour: int) -> List[Dict[str, Any]]:
        """ì‹œê°„ëŒ€ë³„ ì´ìŠˆ ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹œê°„ëŒ€ë³„ ì´ìŠˆ íŠ¹ì„± ë°˜ì˜
        if start_hour == 9:  # ì˜¤ì „ìˆ˜ì—…
            issues = [
                {
                    "number": 15,
                    "title": "ìˆ˜ì—… ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ í•´ê²° í•„ìš”",
                    "state": "open",
                    "created_at": f"{target_date}T10:45:00Z",
                    "type": "í•™ìŠµì§ˆë¬¸"
                }
            ]
        elif start_hour == 13:  # ì˜¤í›„ìˆ˜ì—…
            issues = []  # ì˜¤í›„ëŠ” ì‹¤ìŠµì— ì§‘ì¤‘
        else:  # ì €ë…ììœ¨í•™ìŠµ
            issues = [
                {
                    "number": 16,
                    "title": "ê°œì¸ í”„ë¡œì íŠ¸ ê¸°ëŠ¥ ê°œì„  ì•„ì´ë””ì–´",
                    "state": "open", 
                    "created_at": f"{target_date}T20:30:00Z",
                    "type": "ê¸°ëŠ¥ì œì•ˆ"
                },
                {
                    "number": 17,
                    "title": "ì½”ë“œ ë¦¬íŒ©í† ë§ ê³„íš",
                    "state": "closed",
                    "created_at": f"{target_date}T21:15:00Z",
                    "type": "ê°œì„ ê³„íš"
                }
            ]
        
        logger.info(f"ì‹œê°„ëŒ€ë³„ ì´ìŠˆ ìˆ˜ì§‘: {len(issues)}ê°œ ({start_hour}:00-{end_hour}:00)")
        return issues

    def _get_prs_by_time_range(self, target_date: date, start_hour: int, end_hour: int) -> List[Dict[str, Any]]:
        """ì‹œê°„ëŒ€ë³„ Pull Request ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹œê°„ëŒ€ë³„ PR íŠ¹ì„± ë°˜ì˜
        if start_hour == 19:  # ì €ë…ììœ¨í•™ìŠµì—ì„œ ì£¼ë¡œ PR ìƒì„±
            prs = [
                {
                    "number": 8,
                    "title": "ê°œì¸ í”„ë¡œì íŠ¸ ì£¼ìš” ê¸°ëŠ¥ ì™„ì„±",
                    "state": "open",
                    "created_at": f"{target_date}T20:45:00Z",
                    "additions": 256,
                    "deletions": 89,
                    "changed_files": 15,
                    "type": "ê¸°ëŠ¥ì™„ì„±"
                }
            ]
        else:
            prs = []  # ë‹¤ë¥¸ ì‹œê°„ëŒ€ì—ëŠ” PRì´ ì ìŒ
        
        logger.info(f"ì‹œê°„ëŒ€ë³„ PR ìˆ˜ì§‘: {len(prs)}ê°œ ({start_hour}:00-{end_hour}:00)")
        return prs

    def _get_reviews_by_time_range(self, target_date: date, start_hour: int, end_hour: int) -> List[Dict[str, Any]]:
        """ì‹œê°„ëŒ€ë³„ ì½”ë“œ ë¦¬ë·° ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì €ë… ì‹œê°„ëŒ€ì— ì½”ë“œ ë¦¬ë·° í™œë™
        if start_hour == 19:
            reviews = [
                {
                    "pr_number": 7,
                    "state": "approved",
                    "submitted_at": f"{target_date}T21:00:00Z",
                    "type": "ì½”ë“œë¦¬ë·°"
                }
            ]
        else:
            reviews = []
        
        logger.info(f"ì‹œê°„ëŒ€ë³„ ë¦¬ë·° ìˆ˜ì§‘: {len(reviews)}ê°œ ({start_hour}:00-{end_hour}:00)")
        return reviews

    def _calculate_time_part_productivity(self, activities: Dict[str, Any]) -> int:
        """ì‹œê°„ëŒ€ë³„ ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0
            
            # í™œë™ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            score += len(activities.get("commits", [])) * self.activity_weights["commits"]
            score += len(activities.get("issues", [])) * self.activity_weights["issues"] 
            score += len(activities.get("pull_requests", [])) * self.activity_weights["pull_requests"]
            score += len(activities.get("code_reviews", [])) * self.activity_weights["code_reviews"]
            
            # ì»¤ë°‹ì˜ ì§ˆì  ì ìˆ˜ ì¶”ê°€
            for commit in activities.get("commits", []):
                # ì¶”ê°€/ì‚­ì œëœ ë¼ì¸ ìˆ˜ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
                lines_changed = commit.get("additions", 0) + commit.get("deletions", 0)
                if lines_changed > 100:
                    score += 5  # ëŒ€ê·œëª¨ ë³€ê²½
                elif lines_changed > 50:
                    score += 3  # ì¤‘ê°„ ê·œëª¨ ë³€ê²½
                else:
                    score += 1  # ì†Œê·œëª¨ ë³€ê²½
            
            # PRì˜ ì§ˆì  ì ìˆ˜ ì¶”ê°€
            for pr in activities.get("pull_requests", []):
                files_changed = pr.get("changed_files", 0)
                if files_changed > 10:
                    score += 10  # ëŒ€ê·œëª¨ PR
                elif files_changed > 5:
                    score += 7   # ì¤‘ê°„ ê·œëª¨ PR
                else:
                    score += 5   # ì†Œê·œëª¨ PR
            
            # ìµœëŒ€ 100ì ìœ¼ë¡œ ì œí•œ
            final_score = min(score, 100)
            
            logger.info(f"ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {final_score}ì ")
            return final_score
            
        except Exception as e:
            logger.error(f"ìƒì‚°ì„± ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0

    def analyze_daily_github_pattern(self, target_date: date) -> Dict[str, Any]:
        """ì¼ì¼ GitHub í™œë™ íŒ¨í„´ ë¶„ì„"""
        logger.info(f"ì¼ì¼ GitHub íŒ¨í„´ ë¶„ì„ ì‹œì‘: {target_date}")
        
        daily_analysis = {
            "date": str(target_date),
            "time_parts": {},
            "total_score": 0,
            "most_productive_time": "",
            "activity_distribution": {},
            "recommendations": []
        }
        
        # ê° ì‹œê°„ëŒ€ë³„ ë¶„ì„
        for time_part in self.time_ranges.keys():
            activities = self.get_time_part_activities(target_date, time_part)
            if activities:
                daily_analysis["time_parts"][time_part] = activities
                daily_analysis["total_score"] += activities.get("productive_score", 0)
        
        # ê°€ì¥ ìƒì‚°ì ì¸ ì‹œê°„ëŒ€ ì‹ë³„
        if daily_analysis["time_parts"]:
            most_productive = max(
                daily_analysis["time_parts"].items(),
                key=lambda x: x[1].get("productive_score", 0)
            )
            daily_analysis["most_productive_time"] = most_productive[0]
        
        # í™œë™ ë¶„í¬ ê³„ì‚°
        total_commits = sum(len(part.get("commits", [])) for part in daily_analysis["time_parts"].values())
        total_issues = sum(len(part.get("issues", [])) for part in daily_analysis["time_parts"].values())
        total_prs = sum(len(part.get("pull_requests", [])) for part in daily_analysis["time_parts"].values())
        
        daily_analysis["activity_distribution"] = {
            "total_commits": total_commits,
            "total_issues": total_issues,
            "total_pull_requests": total_prs,
            "commits_per_timepart": total_commits / 3 if total_commits > 0 else 0
        }
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
        daily_analysis["recommendations"] = self._generate_recommendations(daily_analysis)
        
        logger.info(f"ì¼ì¼ GitHub íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: ì´ {daily_analysis['total_score']}ì ")
        return daily_analysis

    def _generate_recommendations(self, daily_analysis: Dict[str, Any]) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ê°€ì¥ ìƒì‚°ì ì¸ ì‹œê°„ëŒ€ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        most_productive = daily_analysis.get("most_productive_time", "")
        if most_productive:
            recommendations.append(f"{most_productive} ì‹œê°„ëŒ€ê°€ ê°€ì¥ ìƒì‚°ì ì…ë‹ˆë‹¤. ì¤‘ìš”í•œ ì‘ì—…ì„ ì´ ì‹œê°„ì— ë°°ì¹˜í•˜ì„¸ìš”.")
        
        # í™œë™ ë¶„í¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­  
        distribution = daily_analysis.get("activity_distribution", {})
        total_commits = distribution.get("total_commits", 0)
        total_prs = distribution.get("total_pull_requests", 0)
        
        if total_commits > 10:
            recommendations.append("ì»¤ë°‹ ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤. ë” í° ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ì»¤ë°‹í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        elif total_commits < 3:
            recommendations.append("ì»¤ë°‹ ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤. ë” ìì£¼ ì‘ì€ ë‹¨ìœ„ë¡œ ì»¤ë°‹í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        if total_prs == 0:
            recommendations.append("Pull Requestë¥¼ í™œìš©í•˜ì—¬ ì½”ë“œ ë¦¬ë·° ë° í˜‘ì—…ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
        
        return recommendations

    def save_analysis_report(self, daily_analysis: Dict[str, Any]) -> str:
        """ë¶„ì„ ë³´ê³ ì„œ ì €ì¥"""
        report_dir = "data/github_analysis"
        os.makedirs(report_dir, exist_ok=True)
        
        target_date = daily_analysis.get("date", "unknown")
        filename = f"github_analysis_{target_date.replace('-', '')}.json"
        filepath = os.path.join(report_dir, filename)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        daily_analysis["analysis_timestamp"] = datetime.now().isoformat()
        daily_analysis["analyzer_version"] = "1.0.0"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(daily_analysis, f, ensure_ascii=False, indent=2)
        
        logger.info(f"GitHub ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {filepath}")
        return filepath

    def analyze_commit_messages_by_timepart(self, commits: List[Dict[str, Any]], time_part: str) -> Dict[str, Any]:
        """
        ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„ìœ¼ë¡œ í•™ìŠµ íŒ¨í„´ ì‹ë³„
        Task 4.1.2: ì»¤ë°‹ ë©”ì‹œì§€ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ë° ë¶„ë¥˜
        
        Args:
            commits: ì»¤ë°‹ ë¦¬ìŠ¤íŠ¸
            time_part: ì‹œê°„ëŒ€ ("ğŸŒ… ì˜¤ì „ìˆ˜ì—…", "ğŸŒ ì˜¤í›„ìˆ˜ì—…", "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ")
            
        Returns:
            ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„ ê²°ê³¼
        """
        
        # ì‹œê°„ëŒ€ë³„ í•™ìŠµ íŒ¨í„´ í‚¤ì›Œë“œ ì •ì˜
        patterns = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": {
                "keywords": ["ê°•ì˜", "ìˆ˜ì—…", "ì´ë¡ ", "ê°œë…", "í•™ìŠµ", "ë…¸íŠ¸", "ì •ë¦¬", "ê¸°ì´ˆ", "ë¬¸ë²•", "ì›ë¦¬"],
                "categories": {
                    "theory_learning": ["ì´ë¡ ", "ê°œë…", "ì›ë¦¬", "ê¸°ì´ˆ"],
                    "note_taking": ["ë…¸íŠ¸", "ì •ë¦¬", "ìš”ì•½", "ë©”ëª¨"],
                    "lecture_content": ["ê°•ì˜", "ìˆ˜ì—…", "í•™ìŠµ", "ì„¤ëª…"],
                    "basic_practice": ["ì˜ˆì œ", "ê¸°ì´ˆ", "ì—°ìŠµ", "ë¬¸ë²•"]
                }
            },
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": {
                "keywords": ["ì‹¤ìŠµ", "í”„ë¡œì íŠ¸", "êµ¬í˜„", "ì‹¤í–‰", "í…ŒìŠ¤íŠ¸", "ê³¼ì œ", "ê¸°ëŠ¥", "ê°œë°œ", "ì™„ì„±", "ì ìš©"],
                "categories": {
                    "hands_on_practice": ["ì‹¤ìŠµ", "ì‹¤í–‰", "ì—°ìŠµ", "ë”°ë¼í•˜ê¸°"],
                    "project_work": ["í”„ë¡œì íŠ¸", "ê³¼ì œ", "ì‘ì—…", "ê°œë°œ"],
                    "implementation": ["êµ¬í˜„", "ê°œë°œ", "ì™„ì„±", "ì‘ì„±"],
                    "testing_debugging": ["í…ŒìŠ¤íŠ¸", "ë””ë²„ê¹…", "ìˆ˜ì •", "ê°œì„ "]
                }
            },
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": {
                "keywords": ["ë³µìŠµ", "ììœ¨", "ê°œì¸", "ì •ë¦¬", "ì˜ˆìŠµ", "ì—°êµ¬", "ì‹¤í—˜", "ì‹¬í™”", "ê°œì„ ", "í™•ì¥"],
                "categories": {
                    "review_study": ["ë³µìŠµ", "ì •ë¦¬", "ìš”ì•½", "ì¬í•™ìŠµ"],
                    "personal_project": ["ê°œì¸", "ììœ¨", "í”„ë¡œì íŠ¸", "ì‹¤í—˜"],
                    "advanced_learning": ["ì‹¬í™”", "í™•ì¥", "ê³ ê¸‰", "ì¶”ê°€"],
                    "research_exploration": ["ì—°êµ¬", "íƒêµ¬", "ë¶„ì„", "ì¡°ì‚¬"]
                }
            }
        }
        
        if time_part not in patterns:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‹œê°„ëŒ€: {time_part}")
            return {}
        
        time_patterns = patterns[time_part]
        
        analysis = {
            "time_part": time_part,
            "total_commits": len(commits),
            "analyzed_at": datetime.now().isoformat(),
            "pattern_analysis": {
                "matching_keywords": [],
                "pattern_match_rate": 0.0,
                "dominant_pattern": "",
                "learning_focus_areas": []
            },
            "category_distribution": {
                category: 0 for category in time_patterns["categories"].keys()
            },
            "commit_classification": [],
            "learning_insights": {
                "primary_activity": "",
                "secondary_activity": "",
                "learning_depth": "shallow",  # shallow, moderate, deep
                "collaboration_level": "individual"  # individual, collaborative
            },
            "recommendations": []
        }
        
        if not commits:
            return analysis
        
        # ê° ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„
        matched_keywords = set()
        category_counts = {category: 0 for category in time_patterns["categories"].keys()}
        
        for commit in commits:
            message = commit.get("message", "").lower()
            commit_analysis = {
                "sha": commit.get("sha", "unknown"),
                "message": commit.get("message", ""),
                "timestamp": commit.get("timestamp", ""),
                "matched_keywords": [],
                "categories": [],
                "learning_type": "unknown",
                "complexity_level": "basic"
            }
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in time_patterns["keywords"]:
                if keyword in message:
                    matched_keywords.add(keyword)
                    commit_analysis["matched_keywords"].append(keyword)
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            for category, category_keywords in time_patterns["categories"].items():
                for keyword in category_keywords:
                    if keyword in message:
                        category_counts[category] += 1
                        commit_analysis["categories"].append(category)
                        break
            
            # í•™ìŠµ ìœ í˜• ë° ë³µì¡ë„ ë¶„ì„
            commit_analysis["learning_type"] = self._determine_learning_type(message, time_part)
            commit_analysis["complexity_level"] = self._determine_complexity_level(commit)
            
            analysis["commit_classification"].append(commit_analysis)
        
        # íŒ¨í„´ ë¶„ì„ ì™„ë£Œ
        analysis["pattern_analysis"]["matching_keywords"] = list(matched_keywords)
        analysis["pattern_analysis"]["pattern_match_rate"] = (
            len(matched_keywords) / len(time_patterns["keywords"]) * 100
        )
        
        # ì§€ë°°ì  íŒ¨í„´ ì‹ë³„
        if category_counts:
            dominant_category = max(category_counts.items(), key=lambda x: x[1])
            analysis["pattern_analysis"]["dominant_pattern"] = dominant_category[0]
        
        # ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì—…ë°ì´íŠ¸
        analysis["category_distribution"] = category_counts
        
        # í•™ìŠµ ì´ˆì  ì˜ì—­ ì‹ë³„
        focus_areas = [category for category, count in category_counts.items() if count > 0]
        analysis["pattern_analysis"]["learning_focus_areas"] = focus_areas
        
        # í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        analysis["learning_insights"] = self._generate_learning_insights(
            category_counts, commits, time_part
        )
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
        analysis["recommendations"] = self._generate_timepart_recommendations(
            analysis, time_part
        )
        
        logger.info(f"ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„ ì™„ë£Œ - {time_part}: {len(commits)}ê°œ ì»¤ë°‹, "
                   f"ë§¤ì¹­ë¥  {analysis['pattern_analysis']['pattern_match_rate']:.1f}%")
        
        return analysis
    
    def _determine_learning_type(self, message: str, time_part: str) -> str:
        """ì»¤ë°‹ ë©”ì‹œì§€ë¡œë¶€í„° í•™ìŠµ ìœ í˜• ê²°ì •"""
        message_lower = message.lower()
        
        # í•™ìŠµ ìœ í˜• íŒ¨í„´
        learning_types = {
            "theoretical": ["ì´ë¡ ", "ê°œë…", "ì›ë¦¬", "ì •ì˜", "ì„¤ëª…"],
            "practical": ["ì‹¤ìŠµ", "êµ¬í˜„", "ì‹¤í–‰", "í…ŒìŠ¤íŠ¸", "ì ìš©"],
            "creative": ["í”„ë¡œì íŠ¸", "ì°½ì‘", "ê°œë°œ", "ì„¤ê³„", "ì‹¤í—˜"],
            "review": ["ë³µìŠµ", "ì •ë¦¬", "ìš”ì•½", "ì¬ì •ë¦¬", "ì ê²€"],
            "research": ["ì—°êµ¬", "íƒêµ¬", "ë¶„ì„", "ì¡°ì‚¬", "ì‹¬í™”"]
        }
        
        for learning_type, keywords in learning_types.items():
            if any(keyword in message_lower for keyword in keywords):
                return learning_type
        
        # ê¸°ë³¸ê°’: ì‹œê°„ëŒ€ì— ë”°ë¥¸ ì¶”ì •
        defaults = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": "theoretical",
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": "practical", 
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": "creative"
        }
        
        return defaults.get(time_part, "unknown")
    
    def _determine_complexity_level(self, commit: Dict[str, Any]) -> str:
        """ì»¤ë°‹ì˜ ë³µì¡ë„ ìˆ˜ì¤€ ê²°ì •"""
        additions = commit.get("additions", 0)
        deletions = commit.get("deletions", 0)
        files_changed = commit.get("files_changed", 1)
        
        total_changes = additions + deletions
        
        if total_changes > 200 or files_changed > 10:
            return "advanced"
        elif total_changes > 50 or files_changed > 5:
            return "intermediate"
        else:
            return "basic"
    
    def _generate_learning_insights(self, category_counts: Dict[str, int], 
                                   commits: List[Dict[str, Any]], time_part: str) -> Dict[str, str]:
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = {
            "primary_activity": "",
            "secondary_activity": "",
            "learning_depth": "shallow",
            "collaboration_level": "individual"
        }
        
        # ì£¼ìš”/ë³´ì¡° í™œë™ ì‹ë³„
        sorted_categories = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)
        if sorted_categories:
            insights["primary_activity"] = sorted_categories[0][0]
            if len(sorted_categories) > 1:
                insights["secondary_activity"] = sorted_categories[1][0]
        
        # í•™ìŠµ ê¹Šì´ í‰ê°€
        total_commits = len(commits)
        if total_commits > 5:
            insights["learning_depth"] = "deep"
        elif total_commits > 2:
            insights["learning_depth"] = "moderate"
        
        # í˜‘ì—… ìˆ˜ì¤€ í‰ê°€ (PR, ë¦¬ë·° ê¸°ë°˜)
        # ì´ ë¶€ë¶„ì€ ì¶”í›„ ì‹¤ì œ GitHub ë°ì´í„° ì—°ë™ ì‹œ ê°œì„ 
        
        return insights
    
    def _generate_timepart_recommendations(self, analysis: Dict[str, Any], time_part: str) -> List[str]:
        """ì‹œê°„ëŒ€ë³„ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        pattern_match_rate = analysis["pattern_analysis"]["pattern_match_rate"]
        total_commits = analysis["total_commits"]
        category_dist = analysis["category_distribution"]
        
        # ì‹œê°„ëŒ€ë³„ íŠ¹í™” ê¶Œì¥ì‚¬í•­
        timepart_advice = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": {
                "low_activity": "ì˜¤ì „ ì‹œê°„ì— ë” ë§ì€ í•™ìŠµ ë…¸íŠ¸ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "good_pattern": "ì´ë¡  í•™ìŠµ íŒ¨í„´ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. ê³„ì† ìœ ì§€í•˜ì„¸ìš”.",
                "improvement": "ì‹¤ìŠµ ì˜ˆì œë¥¼ ì¶”ê°€í•˜ì—¬ ì´ë¡ ê³¼ ì‹¤ìŠµì˜ ê· í˜•ì„ ë§ì¶°ë³´ì„¸ìš”."
            },
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": {
                "low_activity": "ì˜¤í›„ ì‹¤ìŠµ ì‹œê°„ì„ ë” ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ë³´ì„¸ìš”.",
                "good_pattern": "ì‹¤ìŠµ ë° í”„ë¡œì íŠ¸ ì§„í–‰ì´ í™œë°œí•©ë‹ˆë‹¤.",
                "improvement": "í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±ì„ ëŠ˜ë ¤ ì½”ë“œ í’ˆì§ˆì„ í–¥ìƒì‹œì¼œë³´ì„¸ìš”."
            },
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": {
                "low_activity": "ì €ë… ììœ¨í•™ìŠµ ì‹œê°„ì„ ë” ì²´ê³„ì ìœ¼ë¡œ í™œìš©í•´ë³´ì„¸ìš”.",
                "good_pattern": "ìê¸°ì£¼ë„ì  í•™ìŠµì´ ì˜ ì´ë¤„ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
                "improvement": "ê°œì¸ í”„ë¡œì íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•´ë³´ì„¸ìš”."
            }
        }
        
        advice = timepart_advice.get(time_part, {})
        
        # í™œë™ ìˆ˜ì¤€ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­
        if total_commits == 0:
            recommendations.append(f"ğŸ”” {time_part} ì‹œê°„ëŒ€ì— GitHub í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.")
            recommendations.append(advice.get("low_activity", ""))
        elif total_commits < 3:
            recommendations.append(f"ğŸ“ˆ {time_part} í™œë™ì„ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ë³´ì„¸ìš”.")
        else:
            recommendations.append(advice.get("good_pattern", ""))
        
        # íŒ¨í„´ ë§¤ì¹­ë¥ ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­
        if pattern_match_rate < 30:
            recommendations.append(f"ğŸ’¡ {time_part}ì— ì í•©í•œ í™œë™ íŒ¨í„´ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
        elif pattern_match_rate > 70:
            recommendations.append(f"ğŸ¯ {time_part} í•™ìŠµ íŒ¨í„´ì´ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        
        # ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ê¶Œì¥ì‚¬í•­
        active_categories = sum(1 for count in category_dist.values() if count > 0)
        if active_categories < 2:
            recommendations.append(advice.get("improvement", ""))
        
        return [rec for rec in recommendations if rec] or [f"{time_part} í™œë™ ë¶„ì„ ì™„ë£Œ"]
