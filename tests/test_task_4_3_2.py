"""
Task 4.3.2: ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸

í•˜ë£¨ ë™ì•ˆì˜ 3ê°œ ì‹œê°„ëŒ€ë³„ GitHub í™œë™ì„ ì¢…í•© ë¶„ì„í•˜ì—¬
ìƒì„¸í•œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
from datetime import datetime, date, timedelta
from typing import Dict, List, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.notion_automation.scripts.github_realtime_collector import GitHubRealtimeCollector
from src.notion_automation.core.github_time_analyzer import GitHubTimeAnalyzer

class GitHubDailyAnalysisReporter:
    """ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.github_collector = GitHubRealtimeCollector()
        self.github_analyzer = GitHubTimeAnalyzer()
        
        # ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ (ì €ë… ììœ¨í•™ìŠµì— ë†’ì€ ê°€ì¤‘ì¹˜)
        self.timepart_weights = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": 1.0,
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": 1.2,
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": 1.5
        }
        
        # ë¶„ì„ ê¸°ì¤€
        self.analysis_criteria = {
            "excellent_day": {"total_score": 60, "min_timeparts": 3},
            "good_day": {"total_score": 40, "min_timeparts": 2},
            "average_day": {"total_score": 20, "min_timeparts": 1},
            "improvement_needed": {"total_score": 0, "min_timeparts": 0}
        }
    
    def generate_daily_analysis_report(self, target_date: Optional[date] = None) -> Dict[str, Any]:
        """ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        target_date = target_date or date.today()
        
        print(f"ğŸ“Š {target_date} GitHub í™œë™ ì¢…í•© ë¶„ì„ ì‹œì‘")
        
        # 1. ì‹œê°„ëŒ€ë³„ ë°ì´í„° ìˆ˜ì§‘
        timepart_data = self._collect_all_timepart_data(target_date)
        
        # 2. ì¢…í•© ë¶„ì„ ìˆ˜í–‰
        comprehensive_analysis = self._analyze_daily_github_activity(timepart_data, target_date)
        
        # 3. ìƒì‚°ì„± íŒ¨í„´ ë¶„ì„
        productivity_pattern = self._analyze_productivity_pattern(timepart_data)
        
        # 4. í•™ìŠµ íš¨ìœ¨ì„± ë¶„ì„
        learning_efficiency = self._analyze_learning_efficiency(timepart_data)
        
        # 5. ê°œì„  ì œì•ˆ ìƒì„±
        improvement_suggestions = self._generate_improvement_suggestions(timepart_data, comprehensive_analysis)
        
        # 6. ìµœì¢… ë¦¬í¬íŠ¸ êµ¬ì„±
        daily_report = {
            "analysis_date": target_date.strftime("%Y-%m-%d"),
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "timepart_data": timepart_data,
            "comprehensive_analysis": comprehensive_analysis,
            "productivity_pattern": productivity_pattern,
            "learning_efficiency": learning_efficiency,
            "improvement_suggestions": improvement_suggestions,
            "daily_summary": self._create_daily_summary(comprehensive_analysis, productivity_pattern),
            "next_day_recommendations": self._generate_next_day_recommendations(comprehensive_analysis)
        }
        
        # 7. ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_path = self._save_analysis_report(daily_report, target_date)
        daily_report["report_path"] = report_path
        
        print(f"âœ… ì¼ì¼ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {os.path.basename(report_path)}")
        
        return daily_report
    
    def _collect_all_timepart_data(self, target_date: date) -> Dict[str, Any]:
        """ëª¨ë“  ì‹œê°„ëŒ€ ë°ì´í„° ìˆ˜ì§‘"""
        timepart_data = {}
        
        for time_part in ["ğŸŒ… ì˜¤ì „ìˆ˜ì—…", "ğŸŒ ì˜¤í›„ìˆ˜ì—…", "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ"]:
            try:
                github_data = self.github_collector._collect_simulated_activities(target_date, time_part)
                timepart_data[time_part] = github_data
                print(f"   âœ… {time_part} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ìƒì‚°ì„±: {github_data.get('productive_score', 0)}ì )")
            except Exception as e:
                print(f"   âŒ {time_part} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                timepart_data[time_part] = self._create_empty_timepart_data(time_part)
        
        return timepart_data
    
    def _create_empty_timepart_data(self, time_part: str) -> Dict[str, Any]:
        """ë¹ˆ ì‹œê°„ëŒ€ ë°ì´í„° ìƒì„±"""
        return {
            "date": date.today().strftime("%Y-%m-%d"),
            "time_part": time_part,
            "commits": [],
            "issues": [],
            "pull_requests": [],
            "productive_score": 0,
            "error": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"
        }
    
    def _analyze_daily_github_activity(self, timepart_data: Dict[str, Any], target_date: date) -> Dict[str, Any]:
        """ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„"""
        total_commits = 0
        total_issues = 0
        total_prs = 0
        total_score = 0
        weighted_score = 0
        active_timeparts = 0
        
        timepart_details = {}
        
        for time_part, data in timepart_data.items():
            commits = len(data.get("commits", []))
            issues = len(data.get("issues", []))
            prs = len(data.get("pull_requests", []))
            score = data.get("productive_score", 0)
            weight = self.timepart_weights[time_part]
            
            total_commits += commits
            total_issues += issues
            total_prs += prs
            total_score += score
            weighted_score += score * weight
            
            if score > 0:
                active_timeparts += 1
            
            timepart_details[time_part] = {
                "commits": commits,
                "issues": issues,
                "pull_requests": prs,
                "score": score,
                "weighted_score": score * weight,
                "activity_level": self._determine_activity_level(score)
            }
        
        # ì¼ì¼ í‰ê°€ ë“±ê¸‰ ê²°ì •
        daily_grade = self._determine_daily_grade(total_score, active_timeparts)
        
        return {
            "total_activities": {
                "commits": total_commits,
                "issues": total_issues,
                "pull_requests": total_prs,
                "total_count": total_commits + total_issues + total_prs
            },
            "productivity_scores": {
                "raw_total": total_score,
                "weighted_total": weighted_score,
                "average": total_score / 3,
                "weighted_average": weighted_score / sum(self.timepart_weights.values())
            },
            "timepart_analysis": timepart_details,
            "daily_metrics": {
                "active_timeparts": active_timeparts,
                "completion_rate": active_timeparts / 3 * 100,
                "daily_grade": daily_grade,
                "consistency_score": self._calculate_consistency_score(timepart_details)
            }
        }
    
    def _analyze_productivity_pattern(self, timepart_data: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒì‚°ì„± íŒ¨í„´ ë¶„ì„"""
        timepart_scores = {}
        for time_part, data in timepart_data.items():
            timepart_scores[time_part] = data.get("productive_score", 0)
        
        # ìµœê³ /ìµœì € ìƒì‚°ì„± ì‹œê°„ëŒ€
        max_timepart = max(timepart_scores.keys(), key=lambda k: timepart_scores[k])
        min_timepart = min(timepart_scores.keys(), key=lambda k: timepart_scores[k])
        
        # ìƒì‚°ì„± ë³€í™” íŒ¨í„´
        scores = [timepart_scores["ğŸŒ… ì˜¤ì „ìˆ˜ì—…"], timepart_scores["ğŸŒ ì˜¤í›„ìˆ˜ì—…"], timepart_scores["ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ"]]
        trend = self._analyze_trend(scores)
        
        # ì‹œê°„ëŒ€ë³„ íŠ¹ì„± ë¶„ì„
        timepart_characteristics = {}
        for time_part, data in timepart_data.items():
            commits = data.get("commits", [])
            timepart_characteristics[time_part] = {
                "dominant_activity": self._identify_dominant_activity(data),
                "commit_frequency": len(commits),
                "average_commit_size": self._calculate_average_commit_size(commits),
                "work_pattern": self._analyze_work_pattern(commits)
            }
        
        return {
            "peak_productivity": {
                "timepart": max_timepart,
                "score": timepart_scores[max_timepart]
            },
            "lowest_productivity": {
                "timepart": min_timepart,
                "score": timepart_scores[min_timepart]
            },
            "productivity_trend": trend,
            "productivity_distribution": timepart_scores,
            "timepart_characteristics": timepart_characteristics,
            "optimal_schedule": self._suggest_optimal_schedule(timepart_scores)
        }
    
    def _analyze_learning_efficiency(self, timepart_data: Dict[str, Any]) -> Dict[str, Any]:
        """í•™ìŠµ íš¨ìœ¨ì„± ë¶„ì„"""
        learning_metrics = {}
        
        for time_part, data in timepart_data.items():
            commits = data.get("commits", [])
            
            # ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„
            if commits:
                commit_analysis = self.github_analyzer.analyze_commit_messages_by_timepart(commits, time_part)
                learning_metrics[time_part] = {
                    "learning_focus": commit_analysis.get("learning_categories", {}),
                    "complexity_distribution": commit_analysis.get("complexity_levels", {}),
                    "productivity_indicators": commit_analysis.get("productivity_indicators", {}),
                    "learning_efficiency_score": self._calculate_learning_efficiency_score(commit_analysis)
                }
            else:
                learning_metrics[time_part] = {
                    "learning_focus": {},
                    "complexity_distribution": {},
                    "productivity_indicators": {},
                    "learning_efficiency_score": 0
                }
        
        # ì „ì²´ í•™ìŠµ íš¨ìœ¨ì„± ì¢…í•©
        total_efficiency = sum(
            metrics.get("learning_efficiency_score", 0) 
            for metrics in learning_metrics.values()
        ) / len(learning_metrics)
        
        # ìµœì  í•™ìŠµ ì‹œê°„ëŒ€ ì‹ë³„
        best_learning_timepart = max(
            learning_metrics.keys(),
            key=lambda tp: learning_metrics[tp].get("learning_efficiency_score", 0)
        )
        
        return {
            "timepart_learning_metrics": learning_metrics,
            "overall_efficiency_score": total_efficiency,
            "best_learning_timepart": best_learning_timepart,
            "learning_pattern_insights": self._generate_learning_insights(learning_metrics)
        }
    
    def _generate_improvement_suggestions(self, timepart_data: Dict[str, Any], 
                                        comprehensive_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ìƒì‚°ì„± ê¸°ë°˜ ì œì•ˆ
        daily_grade = comprehensive_analysis["daily_metrics"]["daily_grade"]
        active_timeparts = comprehensive_analysis["daily_metrics"]["active_timeparts"]
        
        if daily_grade == "improvement_needed":
            suggestions.append({
                "category": "ì „ì²´ ìƒì‚°ì„±",
                "priority": "ë†’ìŒ",
                "suggestion": "ì „ë°˜ì ì¸ GitHub í™œë™ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê° ì‹œê°„ëŒ€ë³„ë¡œ ìµœì†Œ 1ê°œ ì´ìƒì˜ ì»¤ë°‹ì„ ëª©í‘œë¡œ ì„¤ì •í•´ë³´ì„¸ìš”.",
                "action_items": [
                    "ì˜¤ì „: ê¸°ì´ˆ ê°œë… ì •ë¦¬ ì»¤ë°‹ ì‘ì„±",
                    "ì˜¤í›„: ì‹¤ìŠµ ì½”ë“œ ì»¤ë°‹ ì—…ë¡œë“œ",
                    "ì €ë…: ê°œì¸ í”„ë¡œì íŠ¸ ì§„í–‰"
                ]
            })
        
        if active_timeparts < 3:
            suggestions.append({
                "category": "ì‹œê°„ëŒ€ ê· í˜•",
                "priority": "ì¤‘ê°„",
                "suggestion": f"í™œë™í•œ ì‹œê°„ëŒ€ê°€ {active_timeparts}/3ê°œì…ë‹ˆë‹¤. ëª¨ë“  ì‹œê°„ëŒ€ì—ì„œ ê· í˜•ìˆëŠ” í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                "action_items": [
                    "ë¹„í™œì„± ì‹œê°„ëŒ€ì— ìµœì†Œí•œì˜ í•™ìŠµ í™œë™ ê³„íš",
                    "ì‹œê°„ëŒ€ë³„ í•™ìŠµ ëª©í‘œ ì¬ì„¤ì •"
                ]
            })
        
        # ì‹œê°„ëŒ€ë³„ íŠ¹í™” ì œì•ˆ
        for time_part, data in timepart_data.items():
            score = data.get("productive_score", 0)
            if score < 10:
                suggestions.append({
                    "category": f"{time_part} ê°œì„ ",
                    "priority": "ì¤‘ê°„",
                    "suggestion": f"{time_part} ì‹œê°„ëŒ€ì˜ ìƒì‚°ì„±ì´ ë‚®ìŠµë‹ˆë‹¤ ({score}ì ).",
                    "action_items": self._get_timepart_improvement_actions(time_part)
                })
        
        return suggestions
    
    def _get_timepart_improvement_actions(self, time_part: str) -> List[str]:
        """ì‹œê°„ëŒ€ë³„ ê°œì„  ì•¡ì…˜ ì•„ì´í…œ"""
        actions = {
            "ğŸŒ… ì˜¤ì „ìˆ˜ì—…": [
                "ìˆ˜ì—… ë‚´ìš© ìš”ì•½ ì •ë¦¬",
                "ê¸°ì´ˆ ê°œë… ì˜ˆì œ ì½”ë“œ ì‘ì„±",
                "ì´í•´í•˜ì§€ ëª»í•œ ë¶€ë¶„ ì´ìŠˆ ë“±ë¡"
            ],
            "ğŸŒ ì˜¤í›„ìˆ˜ì—…": [
                "ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì½”ë“œ ì™„ì„±",
                "ì˜¤ì „ í•™ìŠµ ë‚´ìš© ì‹¤ìŠµ ì ìš©",
                "ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ê°œì„ "
            ],
            "ğŸŒ™ ì €ë…ììœ¨í•™ìŠµ": [
                "ê°œì¸ í”„ë¡œì íŠ¸ ì§„í–‰",
                "í•˜ë£¨ í•™ìŠµ ë‚´ìš© ì¢…í•© ì •ë¦¬",
                "ë‚´ì¼ í•™ìŠµ ê³„íš ìˆ˜ë¦½"
            ]
        }
        return actions.get(time_part, ["í•´ë‹¹ ì‹œê°„ëŒ€ í™œë™ ì¦ê°€"])
    
    def _determine_daily_grade(self, total_score: int, active_timeparts: int) -> str:
        """ì¼ì¼ í‰ê°€ ë“±ê¸‰ ê²°ì •"""
        for grade, criteria in self.analysis_criteria.items():
            if (total_score >= criteria["total_score"] and 
                active_timeparts >= criteria["min_timeparts"]):
                return grade
        return "improvement_needed"
    
    def _determine_activity_level(self, score: int) -> str:
        """í™œë™ ìˆ˜ì¤€ ê²°ì •"""
        if score >= 25:
            return "ë§¤ìš° í™œë°œ"
        elif score >= 15:
            return "í™œë°œ"
        elif score >= 5:
            return "ë³´í†µ"
        elif score > 0:
            return "ë‚®ìŒ"
        else:
            return "ë¹„í™œì„±"
    
    def _calculate_consistency_score(self, timepart_details: Dict[str, Any]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        scores = [details["score"] for details in timepart_details.values()]
        if not scores or max(scores) == 0:
            return 0
        
        mean_score = sum(scores) / len(scores)
        variance = sum((score - mean_score) ** 2 for score in scores) / len(scores)
        std_dev = variance ** 0.5
        
        # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„±ì´ ë†’ìŒ
        consistency = max(0, 100 - (std_dev / mean_score * 100)) if mean_score > 0 else 0
        return round(consistency, 1)
    
    def _analyze_trend(self, scores: List[int]) -> str:
        """ì ìˆ˜ ë³€í™” íŠ¸ë Œë“œ ë¶„ì„"""
        if len(scores) < 2:
            return "ë¶„ì„ ë¶ˆê°€"
        
        increasing = sum(scores[i] < scores[i+1] for i in range(len(scores)-1))
        decreasing = sum(scores[i] > scores[i+1] for i in range(len(scores)-1))
        
        if increasing > decreasing:
            return "ìƒìŠ¹ íŠ¸ë Œë“œ"
        elif decreasing > increasing:
            return "í•˜ë½ íŠ¸ë Œë“œ"
        else:
            return "ì¼ì •í•œ íŠ¸ë Œë“œ"
    
    def _identify_dominant_activity(self, data: Dict[str, Any]) -> str:
        """ì£¼ìš” í™œë™ ìœ í˜• ì‹ë³„"""
        activities = {
            "ì»¤ë°‹": len(data.get("commits", [])),
            "ì´ìŠˆ": len(data.get("issues", [])),
            "PR": len(data.get("pull_requests", []))
        }
        
        if sum(activities.values()) == 0:
            return "í™œë™ ì—†ìŒ"
        
        return max(activities.keys(), key=lambda k: activities[k])
    
    def _calculate_average_commit_size(self, commits: List[Dict[str, Any]]) -> Dict[str, float]:
        """í‰ê·  ì»¤ë°‹ í¬ê¸° ê³„ì‚°"""
        if not commits:
            return {"additions": 0, "deletions": 0, "files_changed": 0}
        
        total_additions = sum(commit.get("additions", 0) for commit in commits)
        total_deletions = sum(commit.get("deletions", 0) for commit in commits)
        total_files = sum(commit.get("files_changed", 0) for commit in commits)
        
        return {
            "additions": total_additions / len(commits),
            "deletions": total_deletions / len(commits),
            "files_changed": total_files / len(commits)
        }
    
    def _analyze_work_pattern(self, commits: List[Dict[str, Any]]) -> str:
        """ì‘ì—… íŒ¨í„´ ë¶„ì„"""
        if not commits:
            return "í™œë™ ì—†ìŒ"
        
        avg_size = self._calculate_average_commit_size(commits)
        
        if avg_size["additions"] > 50:
            return "ëŒ€ê·œëª¨ ê°œë°œ"
        elif avg_size["additions"] > 20:
            return "ì¤‘ê°„ ê·œëª¨ ê°œë°œ"
        else:
            return "ì†Œê·œëª¨ ìˆ˜ì •"
    
    def _suggest_optimal_schedule(self, timepart_scores: Dict[str, int]) -> List[str]:
        """ìµœì  ìŠ¤ì¼€ì¤„ ì œì•ˆ"""
        sorted_timeparts = sorted(timepart_scores.items(), key=lambda x: x[1], reverse=True)
        
        suggestions = []
        for i, (timepart, score) in enumerate(sorted_timeparts):
            if i == 0:
                suggestions.append(f"{timepart}: ê°€ì¥ ìƒì‚°ì ì¸ ì‹œê°„ëŒ€, ì¤‘ìš”í•œ ì‘ì—… ìš°ì„  ë°°ì¹˜")
            elif i == 1:
                suggestions.append(f"{timepart}: ì¤‘ê°„ ìƒì‚°ì„±, ì‹¤ìŠµ ë° ì—°ìŠµ í™œë™ ê¶Œì¥")
            else:
                suggestions.append(f"{timepart}: ìƒì‚°ì„± ê°œì„  í•„ìš”, ê¸°ì´ˆ í•™ìŠµ ë° ë³µìŠµ í™œë™")
        
        return suggestions
    
    def _calculate_learning_efficiency_score(self, commit_analysis: Dict[str, Any]) -> float:
        """í•™ìŠµ íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        # ë³µì¡í•œ ë¡œì§ì´ì§€ë§Œ ê°„ë‹¨íˆ êµ¬í˜„
        categories = commit_analysis.get("learning_categories", {})
        if not categories:
            return 0
        
        # ë‹¤ì–‘í•œ í•™ìŠµ ì¹´í…Œê³ ë¦¬ê°€ ìˆì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        diversity_score = len(categories) * 10
        
        # ìƒì‚°ì„± ì§€í‘œ ë°˜ì˜
        productivity = commit_analysis.get("productivity_indicators", {})
        productivity_score = sum(productivity.values()) if productivity else 0
        
        return min(100, diversity_score + productivity_score)
    
    def _generate_learning_insights(self, learning_metrics: Dict[str, Any]) -> List[str]:
        """í•™ìŠµ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ê° ì‹œê°„ëŒ€ë³„ í•™ìŠµ íŠ¹ì„± ë¶„ì„
        timepart_focus = {}
        for timepart, metrics in learning_metrics.items():
            focus = metrics.get("learning_focus", {})
            if focus:
                dominant_category = max(focus, key=focus.get)
                timepart_focus[timepart] = dominant_category
        
        if timepart_focus:
            insights.append(f"ì‹œê°„ëŒ€ë³„ í•™ìŠµ íŒ¨í„´: {', '.join([f'{tp}({focus})' for tp, focus in timepart_focus.items()])}")
        
        # ì „ì²´ íš¨ìœ¨ì„± í‰ê°€
        efficiency_scores = [
            metrics.get("learning_efficiency_score", 0) 
            for metrics in learning_metrics.values()
        ]
        avg_efficiency = sum(efficiency_scores) / len(efficiency_scores) if efficiency_scores else 0
        
        if avg_efficiency >= 70:
            insights.append("ì „ë°˜ì ìœ¼ë¡œ ë†’ì€ í•™ìŠµ íš¨ìœ¨ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        elif avg_efficiency >= 40:
            insights.append("ì ë‹¹í•œ í•™ìŠµ íš¨ìœ¨ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¢€ ë” ì§‘ì¤‘ì ì¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            insights.append("í•™ìŠµ íš¨ìœ¨ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. í•™ìŠµ ë°©ë²•ê³¼ ì‹œê°„ ê´€ë¦¬ë¥¼ ì ê²€í•´ë³´ì„¸ìš”.")
        
        return insights
    
    def _create_daily_summary(self, comprehensive_analysis: Dict[str, Any], 
                            productivity_pattern: Dict[str, Any]) -> Dict[str, Any]:
        """ì¼ì¼ ìš”ì•½ ìƒì„±"""
        total_activities = comprehensive_analysis["total_activities"]["total_count"]
        daily_grade = comprehensive_analysis["daily_metrics"]["daily_grade"]
        peak_timepart = productivity_pattern["peak_productivity"]["timepart"]
        peak_score = productivity_pattern["peak_productivity"]["score"]
        
        # ë“±ê¸‰ë³„ ì´ëª¨ì§€ ë§¤í•‘
        grade_emoji = {
            "excellent_day": "ğŸŒŸ",
            "good_day": "ğŸ˜Š",
            "average_day": "ğŸ˜",
            "improvement_needed": "ğŸ˜”"
        }
        
        # ë“±ê¸‰ë³„ ë©”ì‹œì§€
        grade_messages = {
            "excellent_day": "í›Œë¥­í•œ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤!",
            "good_day": "ì¢‹ì€ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤!",
            "average_day": "í‰ë²”í•œ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤.",
            "improvement_needed": "ì•„ì‰¬ìš´ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤."
        }
        
        return {
            "emoji": grade_emoji.get(daily_grade, "ğŸ˜"),
            "grade": daily_grade,
            "message": grade_messages.get(daily_grade, ""),
            "total_activities": total_activities,
            "peak_productivity": {
                "timepart": peak_timepart,
                "score": peak_score
            },
            "key_achievement": self._identify_key_achievement(comprehensive_analysis),
            "area_for_improvement": self._identify_improvement_area(comprehensive_analysis)
        }
    
    def _identify_key_achievement(self, analysis: Dict[str, Any]) -> str:
        """ì£¼ìš” ì„±ê³¼ ì‹ë³„"""
        timepart_analysis = analysis["timepart_analysis"]
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ì‹œê°„ëŒ€ì˜ ì„±ê³¼
        best_timepart = max(timepart_analysis, key=lambda tp: timepart_analysis[tp]["score"])
        best_score = timepart_analysis[best_timepart]["score"]
        
        if best_score >= 25:
            return f"{best_timepart}ì—ì„œ ë§¤ìš° ë†’ì€ ìƒì‚°ì„± ë‹¬ì„± ({best_score}ì )"
        elif best_score >= 15:
            return f"{best_timepart}ì—ì„œ ì¢‹ì€ ìƒì‚°ì„± ë‹¬ì„± ({best_score}ì )"
        elif best_score > 0:
            return f"{best_timepart}ì—ì„œ ê¸°ë³¸ì ì¸ í™œë™ ì™„ë£Œ ({best_score}ì )"
        else:
            return "ì˜¤ëŠ˜ì€ íŠ¹ë³„í•œ ì„±ê³¼ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤."
    
    def _identify_improvement_area(self, analysis: Dict[str, Any]) -> str:
        """ê°œì„  ì˜ì—­ ì‹ë³„"""
        timepart_analysis = analysis["timepart_analysis"]
        
        # ê°€ì¥ ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ì€ ì‹œê°„ëŒ€
        worst_timepart = min(timepart_analysis, key=lambda tp: timepart_analysis[tp]["score"])
        worst_score = timepart_analysis[worst_timepart]["score"]
        
        if worst_score == 0:
            return f"{worst_timepart} ì‹œê°„ëŒ€ í™œë™ ë¶€ì¡±"
        elif worst_score < 10:
            return f"{worst_timepart} ì‹œê°„ëŒ€ ìƒì‚°ì„± ê°œì„  í•„ìš”"
        else:
            return "ì „ë°˜ì ì¸ ì¼ê´€ì„± ê°œì„  í•„ìš”"
    
    def _generate_next_day_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ë‚´ì¼ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        daily_grade = analysis["daily_metrics"]["daily_grade"]
        
        if daily_grade == "improvement_needed":
            recommendations.extend([
                "ê° ì‹œê°„ëŒ€ë³„ë¡œ ìµœì†Œ 1ê°œì˜ í•™ìŠµ ëª©í‘œ ì„¤ì •",
                "ì‘ì€ ë‹¨ìœ„ì˜ ì»¤ë°‹ ìŠµê´€ ë§Œë“¤ê¸°",
                "í•™ìŠµ ë‚´ìš©ì„ ì¦‰ì‹œ GitHubì— ê¸°ë¡"
            ])
        elif daily_grade == "average_day":
            recommendations.extend([
                "ìƒì‚°ì„±ì´ ë†’ì•˜ë˜ ì‹œê°„ëŒ€ íŒ¨í„´ ë¶„ì„í•˜ì—¬ ë‹¤ë¥¸ ì‹œê°„ëŒ€ì— ì ìš©",
                "í•™ìŠµ ê¹Šì´ë¥¼ ë†’ì´ê¸° ìœ„í•œ ì‹¬í™” í•™ìŠµ ê³„íš",
                "ì½”ë“œ í’ˆì§ˆ ê°œì„ ì— ì§‘ì¤‘"
            ])
        else:
            recommendations.extend([
                "ì˜¤ëŠ˜ì˜ ì¢‹ì€ íŒ¨í„´ ìœ ì§€",
                "ìƒˆë¡œìš´ ë„ì „ê³¼ì œ ì„¤ì •",
                "í•™ìŠµ ë‚´ìš© ê³µìœ  ë° ì •ë¦¬"
            ])
        
        return recommendations
    
    def _save_analysis_report(self, daily_report: Dict[str, Any], target_date: date) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""
        report_dir = os.path.join(project_root, "logs", "daily_github_analysis")
        os.makedirs(report_dir, exist_ok=True)
        
        # Markdown í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±
        report_filename = f"github_daily_analysis_{target_date.strftime('%Y%m%d')}.md"
        report_path = os.path.join(report_dir, report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            self._write_markdown_report(f, daily_report)
        
        return report_path
    
    def _write_markdown_report(self, file, report: Dict[str, Any]):
        """Markdown í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ ì‘ì„±"""
        file.write(f"# GitHub ì¼ì¼ í™œë™ ë¶„ì„ ë¦¬í¬íŠ¸\n\n")
        file.write(f"**ë¶„ì„ ë‚ ì§œ:** {report['analysis_date']}\n")
        file.write(f"**ìƒì„± ì‹œê°„:** {report['generated_at']}\n\n")
        
        # ì¼ì¼ ìš”ì•½
        summary = report["daily_summary"]
        file.write(f"## {summary['emoji']} ì¼ì¼ ìš”ì•½\n\n")
        file.write(f"**í‰ê°€:** {summary['message']}\n")
        file.write(f"**ì´ í™œë™:** {summary['total_activities']}ê°œ\n")
        file.write(f"**ìµœê³  ìƒì‚°ì„±:** {summary['peak_productivity']['timepart']} ({summary['peak_productivity']['score']}ì )\n")
        file.write(f"**ì£¼ìš” ì„±ê³¼:** {summary['key_achievement']}\n")
        file.write(f"**ê°œì„  ì˜ì—­:** {summary['area_for_improvement']}\n\n")
        
        # ì‹œê°„ëŒ€ë³„ ìƒì„¸ ë¶„ì„
        file.write("## ğŸ“Š ì‹œê°„ëŒ€ë³„ ìƒì„¸ ë¶„ì„\n\n")
        for timepart, details in report["comprehensive_analysis"]["timepart_analysis"].items():
            file.write(f"### {timepart}\n")
            file.write(f"- **ìƒì‚°ì„± ì ìˆ˜:** {details['score']}ì \n")
            file.write(f"- **í™œë™ ìˆ˜ì¤€:** {details['activity_level']}\n")
            file.write(f"- **ì»¤ë°‹:** {details['commits']}ê°œ\n")
            file.write(f"- **ì´ìŠˆ:** {details['issues']}ê°œ\n")
            file.write(f"- **PR:** {details['pull_requests']}ê°œ\n\n")
        
        # ìƒì‚°ì„± íŒ¨í„´
        pattern = report["productivity_pattern"]
        file.write("## ğŸ¯ ìƒì‚°ì„± íŒ¨í„´ ë¶„ì„\n\n")
        file.write(f"**ìƒì‚°ì„± íŠ¸ë Œë“œ:** {pattern['productivity_trend']}\n")
        file.write(f"**ìµœê³  ìƒì‚°ì„± ì‹œê°„ëŒ€:** {pattern['peak_productivity']['timepart']} ({pattern['peak_productivity']['score']}ì )\n")
        file.write(f"**ìµœì € ìƒì‚°ì„± ì‹œê°„ëŒ€:** {pattern['lowest_productivity']['timepart']} ({pattern['lowest_productivity']['score']}ì )\n\n")
        
        # ê°œì„  ì œì•ˆ
        file.write("## ğŸ’¡ ê°œì„  ì œì•ˆ\n\n")
        for suggestion in report["improvement_suggestions"]:
            file.write(f"### {suggestion['category']} (ìš°ì„ ìˆœìœ„: {suggestion['priority']})\n")
            file.write(f"{suggestion['suggestion']}\n\n")
            file.write("**ì•¡ì…˜ ì•„ì´í…œ:**\n")
            for action in suggestion['action_items']:
                file.write(f"- {action}\n")
            file.write("\n")
        
        # ë‚´ì¼ ê¶Œì¥ì‚¬í•­
        file.write("## ğŸš€ ë‚´ì¼ ê¶Œì¥ì‚¬í•­\n\n")
        for rec in report["next_day_recommendations"]:
            file.write(f"- {rec}\n")

def test_github_daily_analysis_reporter():
    """GitHub ì¼ì¼ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Task 4.3.2: ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=======================================================")
    
    reporter = GitHubDailyAnalysisReporter()
    
    # ì¼ì¼ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    today = date.today()
    report = reporter.generate_daily_analysis_report(today)
    
    print(f"\nğŸ“‹ ì¼ì¼ ë¶„ì„ ë¦¬í¬íŠ¸ ìš”ì•½:")
    print(f"   ë‚ ì§œ: {report['analysis_date']}")
    print(f"   í‰ê°€: {report['daily_summary']['message']}")
    print(f"   ì´ í™œë™: {report['daily_summary']['total_activities']}ê°œ")
    print(f"   ìµœê³  ìƒì‚°ì„±: {report['daily_summary']['peak_productivity']['timepart']}")
    print(f"   ì£¼ìš” ì„±ê³¼: {report['daily_summary']['key_achievement']}")
    
    print(f"\nğŸ“Š ì‹œê°„ëŒ€ë³„ ë¶„ì„:")
    for timepart, details in report["comprehensive_analysis"]["timepart_analysis"].items():
        print(f"   {timepart}: {details['score']}ì  ({details['activity_level']})")
    
    print(f"\nğŸ¯ ìƒì‚°ì„± íŒ¨í„´:")
    pattern = report["productivity_pattern"]
    print(f"   íŠ¸ë Œë“œ: {pattern['productivity_trend']}")
    print(f"   ìµœê³  ì‹œê°„ëŒ€: {pattern['peak_productivity']['timepart']}")
    print(f"   ìµœì € ì‹œê°„ëŒ€: {pattern['lowest_productivity']['timepart']}")
    
    print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ ìˆ˜: {len(report['improvement_suggestions'])}ê°œ")
    for suggestion in report["improvement_suggestions"][:2]:  # ìµœëŒ€ 2ê°œë§Œ í‘œì‹œ
        print(f"   - {suggestion['category']}: {suggestion['suggestion'][:50]}...")
    
    print(f"\nğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼: {os.path.basename(report['report_path'])}")
    
    print("\nğŸ‰ Task 4.3.2 ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("âœ… ì¼ì¼ GitHub í™œë™ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ")

if __name__ == "__main__":
    test_github_daily_analysis_reporter()
